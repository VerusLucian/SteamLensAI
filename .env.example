# =============================================================================
# SteamLens AI API Configuration Template
# =============================================================================
# Copy this file to .env and customize the values for your deployment
#
# DEPLOYMENT OPTIONS:
# 1. Local Development: Use localhost URLs for Ollama
# 2. Docker Development: Use host.docker.internal URLs for Ollama
# 3. Production: Configure appropriate URLs and security settings

# =============================================================================
# API Server Configuration
# =============================================================================

# Server binding
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
API_DEBUG=false

# Logging
API_LOG_LEVEL=INFO
API_LOG_FILE=logs/api.log

# =============================================================================
# Rate Limiting Configuration
# =============================================================================

# Daily request limits per IP
RATE_LIMIT_REQUESTS_PER_DAY=100

# Hourly limits per IP for specific endpoints
RATE_LIMIT_QUESTIONS_PER_HOUR=10

# Redis URL for distributed rate limiting (optional)
# REDIS_URL=redis://localhost:6379/0

# =============================================================================
# Firebase Tunnel Support
# =============================================================================

# Trust X-Forwarded-For headers from proxy/tunnel
TRUST_FORWARDED_FOR=true

# Header name for forwarded client IPs
FORWARDED_FOR_HEADER=X-Forwarded-For

# =============================================================================
# Session Management
# =============================================================================

# Session expiration time in hours
SESSION_TIMEOUT_HOURS=24

# Maximum concurrent sessions
MAX_CONCURRENT_SESSIONS=100

# =============================================================================
# Security Configuration
# =============================================================================

# Require API key for access (not implemented yet)
API_KEY_REQUIRED=false

# Allowed CORS origins (comma-separated)
ALLOWED_ORIGINS=*

# =============================================================================
# Ollama Configuration
# =============================================================================

# AI Models (ensure these are downloaded: ollama pull <model-name>)
OLLAMA_EMBED_MODEL=bge-m3
OLLAMA_LLM_MODEL=deepseek-r1:14b

# Ollama API Endpoints
# CHOOSE ONE OPTION BELOW:

# Option 1: Local Development (Ollama running on host machine)
OLLAMA_EMBED_URL=http://localhost:11434/api/embed
OLLAMA_LLM_URL=http://localhost:11434/api/generate

# Option 2: Docker Development (API in container, Ollama on host)
# OLLAMA_EMBED_URL=http://host.docker.internal:11434/api/embed
# OLLAMA_LLM_URL=http://host.docker.internal:11434/api/generate

# Option 3: Production/Remote Ollama
# OLLAMA_EMBED_URL=http://your-ollama-server:11434/api/embed
# OLLAMA_LLM_URL=http://your-ollama-server:11434/api/generate

# Timeout settings (seconds)
OLLAMA_TIMEOUT_EMBED=120
OLLAMA_TIMEOUT_LLM=180

# =============================================================================
# Steam API Configuration
# =============================================================================

# Target number of reviews to download per game
STEAM_TARGET_REVIEWS=1000

# Delay between Steam API requests (seconds)
STEAM_API_SLEEP=0.5

# Maximum review text length
REVIEW_MAX_LENGTH=1024

# =============================================================================
# Embedding and Search Configuration
# =============================================================================

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=10

# Number of similar reviews to retrieve for answering questions
SIMILARITY_TOP_K=40

# =============================================================================
# Application Settings
# =============================================================================

# Directory for storing session data
SAVE_DIR=sessions

# Application language (for internationalization)
APP_LANGUAGE=en

# Internationalization directory
I18N_DIR=i18n

# =============================================================================
# Performance Settings
# =============================================================================

# Maximum concurrent HTTP requests
MAX_CONCURRENT_REQUESTS=5

# HTTP connection pool size
CONNECTION_POOL_SIZE=10

# =============================================================================
# Development Settings
# =============================================================================

# Uncomment these for development/debugging
# API_DEBUG=true
# API_LOG_LEVEL=DEBUG
# API_WORKERS=1
# STEAM_TARGET_REVIEWS=100

# =============================================================================
# Production Settings
# =============================================================================

# Recommended settings for production deployment
# API_DEBUG=false
# API_LOG_LEVEL=INFO
# API_WORKERS=4
# RATE_LIMIT_REQUESTS_PER_DAY=1000
# RATE_LIMIT_QUESTIONS_PER_HOUR=50
# SESSION_TIMEOUT_HOURS=48

# =============================================================================
# Quick Start Examples
# =============================================================================

# 1. Local Development:
#    - Keep localhost URLs above
#    - Run: cd src && python3 -m steam_ai_api.main
#    - Access: http://localhost:8000/docs

# 2. Docker Development:
#    - Uncomment host.docker.internal URLs above
#    - Run: docker-compose up --build
#    - Access: http://localhost:8000/docs

# 3. Testing:
#    - Run: python3 test_api.py --quick